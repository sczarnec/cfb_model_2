---
title: "CFB Game Predictive Model"
author: ""
date: "2024-10-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Install Packages
```{r}
library(tidyverse)
library(ggplot2)
library(rsample)
library(mice)
library(fastDummies)
library(xgboost)
library(Metrics)
library(caret)
library(httr2)
library(readr)
library(cfbfastR)
```

```{r}
source("cfb_app_helpers.R")
```



<br>


## Merge Betting Data with cfbfastR

### Load in Betting Data


```{r}

# betting line data
historical_odds_orig = read.csv("overall_df.csv")

```

```{r}


# Mapping each college name manually

target_names <- c(
  "Hawai'i", "Jacksonville State", "Tennessee-Martin", "Wake Forest", "Maine", "Central Michigan", 
  "Charlotte", "Indiana", "Appalachian State", "North Carolina State", "Utah State", "Rice", 
  "Vanderbilt", "Southern Utah", "Minnesota", "New Mexico", "UNLV", "Eastern Michigan", 
  "Ball State", "Syracuse", "Temple", "Buffalo", "Michigan State", "Baylor", 
  "Colorado State", "Arkansas State", "Stanford", "Nevada", "Boston College", "Bowling Green", 
  "South Alabama", "Maryland", "Fordham", "Houston", "Michigan", "Purdue", 
  "West Virginia", "Northwestern", "Louisiana", "Virginia Tech", "Villanova", "Air Force", 
  "Rutgers", "LSU", "Ohio", "Miami (OH)", "Oklahoma State", "Virginia", 
  "Murray State", "Kent State", "UCLA", "Louisiana Tech", "UC Davis", "Georgia", 
  "James Madison", "Savannah State", "Troy", "North Carolina Central", "Florida A&M", "Florida Atlantic", 
  "East Carolina", "VMI", "UTSA", "Middle Tennessee", "OK Panhandle", "East Tennessee State", 
  "Tulsa", "Memphis", "Kansas", "SMU", "UCF", "Louisiana-Monroe", 
  "Towson", "Southern Miss", "UMass", "Stephen F. Austin", "Washington State", "UTEP", 
  "Nebraska", "Coastal Carolina", "Alabama", "TCU", "Northern Iowa", "New Hampshire", 
  "Auburn", "BYU", "Wyoming", "Northern Arizona", "Old Dominion", "Notre Dame", 
  "Florida State", "Prairie View A&M", "Pittsburgh", "Charleston Southern", "Mercer", "Akron", 
  "Kentucky", "Navy", "Central Connecticut State", "Wofford", "San Jose State", "Idaho", 
  "Idaho State", "Elon", "North Carolina A&T", "Marshall", "North Texas", "Point University", 
  "McNeese", "Georgia Southern", "South Carolina", "South Florida", "Jacksonville", "Iowa", 
  "Illinois", "Tulane", "Sacramento State", "Texas Tech", "California", "Grambling State", 
  "Clemson", "Georgia State", "North Dakota State", "Toledo", "Monmouth", "San Diego State", 
  "Northern Colorado", "New Mexico State", "Western Michigan", "Texas State", "Oklahoma", "Sam Houston", 
  "Portland State", "USC", "Ole Miss", "Wagner", "Duquesne", "Gardner-Webb", 
  "Western Illinois", "Tennessee", "Boise State", "Missouri", "Colorado", "Nicholls State", 
  "Missouri State", "Houston Christian", "Texas A&M", "Arizona", "Alcorn State", "Georgia Tech", 
  "Kennesaw State", "Robert Morris", "Incarnate Word", "Arizona State", "UConn", "Missouri S&T", 
  "Duke", "Oregon", "Fresno State", "Lafayette", "Western Kentucky", "Miami (FL)", 
  "Oregon State", "Abilene Christian", "Iowa State", "Wisconsin", "Kansas State", "Penn State", 
  "Mississippi State", "Utah", "Texas Southern", "Clark Atlanta", "Presbyterian", "Florida", 
  "Tennessee Tech", "Northwestern State", "Morgan State", "The Citadel", "Central Arkansas", "Hampton", 
  "Chattanooga", "Austin Peay", "Tennessee State", "North Dakota", "Arkansas", "Bethune-Cookman", 
  "Youngstown State", "UAB", "Eastern Washington", "Stony Brook", "Southeastern Louisiana", "Louisville", 
  "Eastern Illinois", "Indiana State", "Morehead State", "Arkansas-Pine Bluff", "Montana", "Army", 
  "Alabama A&M", "Southern University", "Texas", "St. Francis (PA)", "Western Carolina", "Ohio State", 
  "Weber State", "University at Albany", "South Dakota", "South Dakota State", "Lamar", "Campbell", 
  "Lehigh", "Norfolk State", "Florida International", "Colgate", "Drake", "Bucknell", 
  "Montana State", "Illinois State", "Cincinnati", "Eastern Kentucky", "Jackson State", "Cal Poly", 
  "South Carolina State", "Southeast Missouri State", "Delaware", "Reinhardt", "Liberty", "North Alabama", 
  "LIU", "Southern Illinois", "Yale", "Tarleton State", "Utah Tech", "Samford", 
  "Davidson", "Bryant", "East Texas A&M", "Rhode Island", "Tusculum", "Delaware State", 
  "Sacred Heart", "Lindenwood"
)

mapped_names <- c(
  "Hawai'i", "Jacksonville State", "", "Wake Forest", "", "Central Michigan", 
  "Charlotte", "Indiana", "App State", "NC State", "Utah State", "Rice", 
  "Vanderbilt", "", "Minnesota", "New Mexico", "UNLV", "Eastern Michigan", 
  "Ball State", "Syracuse", "Temple", "Buffalo", "Michigan State", "Baylor", 
  "Colorado State", "Arkansas State", "Stanford", "Nevada", "Boston College", "Bowling Green", 
  "South Alabama", "Maryland", "", "Houston", "Michigan", "Purdue", 
  "West Virginia", "Northwestern", "Louisiana", "Virginia Tech", "", "Air Force", 
  "Rutgers", "LSU", "Ohio", "Miami (OH)", "Oklahoma State", "Virginia", 
  "", "Kent State", "UCLA", "Louisiana Tech", "", "Georgia", 
  "James Madison", "", "Troy", "", "", "Florida Atlantic", 
  "East Carolina", "", "UTSA", "Middle Tennessee", "", "", 
  "Tulsa", "Memphis", "Kansas", "SMU", "UCF", "UL Monroe", 
  "", "Southern Miss", "Massachusetts", "", "Washington State", "UTEP", 
  "Nebraska", "Coastal Carolina", "Alabama", "TCU", "", "", 
  "Auburn", "BYU", "Wyoming", "", "Old Dominion", "Notre Dame", 
  "Florida State", "", "Pittsburgh", "", "", "Akron", 
  "Kentucky", "Navy", "", "", "San Jose State", "Idaho", 
  "", "", "", "Marshall", "North Texas", "", 
  "", "Georgia Southern", "South Carolina", "South Florida", "", "Iowa", 
  "Illinois", "Tulane", "", "Texas Tech", "California", "", 
  "Clemson", "Georgia State", "", "Toledo", "", "San Diego State", 
  "", "New Mexico State", "Western Michigan", "Texas State", "Oklahoma", "Sam Houston", 
  "", "USC", "Ole Miss", "", "", "", 
  "", "Tennessee", "Boise State", "Missouri", "Colorado", "", 
  "", "Houston Christian", "Texas A&M", "Arizona", "", "Georgia Tech", 
  "Kennesaw State", "", "", "Arizona State", "UConn", "", 
  "Duke", "Oregon", "Fresno State", "", "Western Kentucky", "Miami", 
  "Oregon State", "", "Iowa State", "Wisconsin", "Kansas State", "Penn State", 
  "Mississippi State", "Utah", "", "", "", "Florida", 
  "", "", "", "", "", "", 
  "", "Austin Peay", "", "", "Arkansas", "Bethune-Cookman", 
  "", "UAB", "", "", "", "Louisville", 
  "", "", "", "", "Montana", "Army", 
  "", "", "Texas", "", "", "Ohio State", 
  "", "", "", "", "", "",
  "", "", "Florida International", "", "", "", 
  "", "", "Cincinnati", "", "", "", 
  "", "", "", "", "Liberty", "", 
  "", "", "", "", "", "", 
  "", "", "", "", "", "", "", ""
)




# combine target names and mapped names into a data frame, each in its own row
# create this data frame
name_change_list_t1 = data.frame(team_one = target_names, team1 = mapped_names) 
name_change_list_t2 = data.frame(team_two = target_names, team2 = mapped_names) 

# make betting line college names same as cfbfastr
historical_odds = historical_odds_orig %>% 
  select(team_one, team_two, week, season, home_ml_odds_15, away_ml_odds_15, home_spread_odds_15, home_spread_value_15, away_spread_odds_15, away_spread_value_15, over_odds_15, under_odds_15, over_value_15, under_value_15)
historical_odds = left_join(historical_odds, name_change_list_t1, by = "team_one")
historical_odds = left_join(historical_odds, name_change_list_t2, by = "team_two")
historical_odds_t1 = historical_odds %>% select(-team_one, -team_two)
historical_odds_t2 = historical_odds_t1 %>% rename(team2 = team1, team1 = team2)
historical_odds = bind_rows(historical_odds_t1, historical_odds_t2)
historical_odds = historical_odds %>% rename(t1_team = team1, t2_team = team2)
historical_odds = historical_odds %>% 
  rename(home_ml_odds = home_ml_odds_15,
         away_ml_odds = away_ml_odds_15,
         home_spread_val = home_spread_value_15,
         home_spread_odds = home_spread_odds_15,
         away_spread_val = away_spread_value_15,
         away_spread_odds = away_spread_odds_15,
         over_odds = over_odds_15,
         over_val = over_value_15,
         under_odds = under_odds_15,
         under_val = under_value_15
         ) 



# Keep only non-duplicates
duplicates = duplicated(historical_odds)
historical_odds <- historical_odds[!duplicates, ]





```

```{r}


historical_odds_mod = historical_odds



# create mappings for each week so they can be joined to cfbfastr
historical_odds_mod = historical_odds_mod %>% 
  mutate(type = ifelse(season %in% c(2016,2017,2018, 2021, 2022, 2023) & (week < 14 | week == 15), "reg", ifelse(
                       season %in% c(2016,2017,2018, 2021, 2022, 2023) & week == 14, "cc", ifelse(
                       season %in% c(2016,2017,2018, 2021, 2022, 2023), "post", ifelse(
                       season %in% c(2019,2024,2025) & (week < 15 | week == 16), "reg", ifelse(
                       season %in% c(2019,2024,2025) & week == 15, "cc", ifelse(
                       season %in% c(2019,2024,2025), "post", ifelse(
                       season == 2020 & week <= 15, "reg", ifelse(
                       season == 2020, "post",
                       "nothing"
                       )
                       ) 
  ))))))) %>% 
  select(-c(week))
  
  
  
  # 2019 15 week cc no 16 army navy, same for 2020, same for 2024
  # before 2019 14 week cc 15 navy, same for 2021-23

```

<br>


### Load Pre-Processed cfbfastR Data

```{r, warning=FALSE}

# model data
cfb_data = read.csv(gzfile("cfb_model_data_prep_full_check.csv.gz"))



```


```{r}

# Pre-processing

# current weeks, useful for later predicting this week's games
current_week = 24
current_season = 2024


# df with only rows with both fbs team (fcs data incomplete, easier to exclude these)
# later weeks to let stats accumulate, data before 2015 incomplete 
fbs_only = cfb_data %>% 
  filter(t1_division == "fbs" & t2_division == "fbs") %>% 
  filter(season > 2014)%>% 
  select(-c(t1_division, t2_division)) %>% 
  mutate(conference_game = ifelse(conference_game, 1, 0))
  

# treat NAs, add lag as the stat if there isn't one for a given week
# filter out games that are incomplete, unless for this week
model_prepped_orig = fbs_only %>% 
  filter(((completed == TRUE | (season == current_season & week == current_week)) & !is.na(precipitation_code)) | (week == current_week & season == current_season),
         ) %>% # get rid of non-played games
  
  # replace NAs from pbp with lag for each team/season window, both for t1 and t2
  # best estimate of these stats, if available
  group_by(season, t1_team) %>%
  arrange(t1_team, season, week) %>% 
  mutate(across(starts_with("t1_rol"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup() %>% 
  group_by(season, t2_team) %>% 
  arrange(t2_team, season, week) %>% 
  mutate(across(starts_with("t2_rol"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup() %>% 
  select(-c(rol_win_l1, "rol_loss_l1", "t1_moneyline", "t2_moneyline")) %>% 
  filter(week > 3)



### ml???



```


<br>

### Join the two

```{r}



# create same mappings for cfbfastR data
join_bet = model_prepped_orig %>% 
  mutate(type = ifelse(season %in% c(2015,2016,2017,2018,2021,2022,2023) & (week<14 | week == 15), "reg", ifelse(
                       season %in% c(2015,2016,2017,2018,2021,2022,2023) & week == 14, "cc", ifelse(
                       season %in% c(2015,2016,2017,2018,2021,2022,2023), "post", ifelse(
                       season %in% c(2019, 2020, 2024, 2025) & week < 15, "reg", ifelse(
                       season %in% c(2019, 2020, 2024, 2025) & week == 15, "cc", ifelse(
                       season %in% c(2019, 2020, 2024, 2025), "post",
                       "nothing"
                       )
                       )
                       )
                       )
  )))





# make sure duplicate unique games are out of betting data
fine = historical_odds_mod[!(duplicated(historical_odds_mod[, c("type", "season", "t1_team", "t2_team")]) |
                           duplicated(historical_odds_mod[, c("type", "season", "t1_team", "t2_team")], fromLast = TRUE)), ]
dup = historical_odds_mod[(duplicated(historical_odds_mod[, c("type", "season", "t1_team", "t2_team")]) |
                           duplicated(historical_odds_mod[, c("type", "season", "t1_team", "t2_team")], fromLast = TRUE)), ]
dup = dup %>% filter(!is.na(home_spread_odds))
dup = dup[(duplicated(dup[,c("type", "season", "t1_team", "t2_team")])),]
back = bind_rows(fine, dup)




# join betting data with our predictions
join_bet = left_join(join_bet, back, by = c("t1_team", "t2_team", "type", "season")) %>% 
  select(-c(type)) %>% 
  mutate(t1_ml_odds = ifelse(t1_home == 1, home_ml_odds, away_ml_odds),
         t1_spread_val = ifelse(t1_home == 1, home_spread_val, away_spread_val),
         t1_spread_odds = ifelse(t1_home == 1, home_spread_odds, away_spread_odds),
         t2_ml_odds = ifelse(t1_home == 0, home_ml_odds, away_ml_odds),
         t2_spread_val = ifelse(t1_home == 0, home_spread_val, away_spread_val),
         t2_spread_odds = ifelse(t1_home == 0, home_spread_odds, away_spread_odds)) %>% 
  select(-c(home_ml_odds, away_ml_odds, home_spread_val, away_spread_val, home_spread_odds, away_spread_odds)) %>% 
  mutate(t1_spread_odds = ifelse(is.na(t1_spread_odds), -110, t1_spread_odds),
         t2_spread_odds = ifelse(is.na(t2_spread_odds), -110, t2_spread_odds),
         over_odds = ifelse(is.na(over_odds), -110, over_odds),
         under_odds = ifelse(is.na(under_odds), -110, under_odds))





#### FOR ML MODEL, THROW OUT GAMES WHERE BOOK SPREAD NOT CLOSE TOGETHER, MAYBE 3-5 P1 RANGE


# View(model_prepped_moved %>% filter(neutral_site != 1, season>=2021) %>% select(t1_book_spread, t1_spread_val) %>% mutate(diff = abs(t1_spread_val-t1_book_spread)) %>% group_by(diff) %>% summarize(n = n(), perc = round(n()/dim(model_prepped_moved %>% filter(season>=2021&neutral_site!=1))[1],2)))
# > 
# > View(model_prepped_moved %>% filter(neutral_site != 1, season>=2021) %>% select(t1_book_spread, t1_spread_val, t1_team, t2_team, season, t1_ml_odds) %>% mutate(diff = abs(t1_spread_val-t1_book_spread)))
# 

```


<br>

## Pre-Model Pre-Processing


```{r}

# dummy cols 
model_prepped_dummy = join_bet %>% 
  rename(pc = precipitation_code) %>% 
  dummy_cols('pc') %>% 
  select(-pc)


# rearrange col order (makes easier when looking at predictions later)
move_cols = c("pc_no_rain", "pc_light_rain", "pc_moderate_rain", "pc_heavy_rain", "week","t2_home", "conference_game", "season", "t1_point_diff", "t1_win", "total_points", "t1_points", "t2_points", "game_id", "t1_team", "t2_team", "t1_conference", "t2_conference", "completed", "t1_ml_odds","t2_ml_odds", "t1_spread_val","t1_spread_odds", "t2_spread_val", "t2_spread_odds", "over_odds", "over_val", "under_odds", "under_val")

model_prepped_moved = model_prepped_dummy[, c(setdiff(names(model_prepped_dummy), move_cols), move_cols)]


# get rid of weather cols for now (will be hard to implement in real time)
model_prepped_moved = model_prepped_moved %>% select(-c(grep("rain", names(model_prepped_moved)))) 
model_prepped_moved = model_prepped_moved %>% select(-c(wind_speed, temperature, humidity))

```



### Omit Remaining NA Rows
```{r}

# omit if feature cols are null
cols_to_ignore = c(grep("_val", names(model_prepped_moved)), grep("_odds", names(model_prepped_moved)))
cols_to_check <- setdiff(seq_along(model_prepped_moved), cols_to_ignore)
model_prepped_omit <- model_prepped_moved[complete.cases(model_prepped_moved[, cols_to_check]), ]


# maybe get rid of omit???

# this week's matchups (save for app)
model_prepped_this_week = model_prepped_omit %>% filter(season == current_season & week == 7)
#write.csv(model_prepped_this_week, "model_prepped_this_week.csv")



```





## Run Models

### Point Diff

```{r}


# tuned parameters
parameters = list(eta = .05,
              max.depth = 3, # Set max depth
              min_child_weight = 7, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
              subsample = .8, # Set proportion of training data to use in tree
              colsample_bytree = 1,
              
              
              nrounds = 110 , # Set number of rounds
              early_stopping_rounds = 30, # Set number of rounds to stop at if there is no improvement)
              
              verbose = 0, # 1 - Prints out fit
              nthread = 1,
              
              objective = "reg:squarederror",
              eval_metric = "rmse")

# the pd model
pd_model = model_func("t1_point_diff", model_prepped_omit, 6, 2024, 23, 2015, 1, parameters)


```


```{r}

# Record betting accuracy


pred_dat_final_pd = pd_model
#write.csv(pd_model, "dynamic_vi_model.csv")


# modify col names and calculate predicted scores
pred_dat_final_pd = pred_dat_final_pd %>% 
  rename(pred_t1_point_diff = preds,
         actual_t1_point_diff = oc_var)




### SWITCH TO HOME/AWAY EVENTUALLY

pred_dat_final_pd$id_max = pmax(pred_dat_final_pd$t1_team, pred_dat_final_pd$t2_team)
pred_dat_final_pd$id_min = pmin(pred_dat_final_pd$t1_team, pred_dat_final_pd$t2_team)




# flip duplicate games and aggregate
merge_preds_pd = pred_dat_final_pd %>% 
  mutate(pred_t1_point_diff = ifelse(t1_team == id_max,pred_t1_point_diff, 
                                     pred_t1_point_diff*-1)) %>% 
  group_by(game_id) %>% 
  summarise(pred_t1_point_diff = mean(pred_t1_point_diff))

pred_dat_final_pd = pred_dat_final_pd %>% 
  filter(t1_team == id_max) %>% 
  select(-c(pred_t1_point_diff)) %>% 
  left_join(merge_preds_pd, by = c("game_id"))%>% 
  mutate(pred_t1_point_diff = round(pred_t1_point_diff, 2)) %>% 
  select(-c(id_min, id_max))




write.csv(pred_dat_final_pd, "pred_dat_final_pd.csv")





```


<br>

### Win Probability

```{r}


# tuned parameters
parameters = list(eta = .05,
              max.depth = 3, # Set max depth
              min_child_weight = 7, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
              subsample = .8, # Set proportion of training data to use in tree
              colsample_bytree = 1,
              
              
              nrounds = 110 , # Set number of rounds
              early_stopping_rounds = 30, # Set number of rounds to stop at if there is no improvement)
              
              verbose = 0, # 1 - Prints out fit
              nthread = 1,
              
              objective = "binary:logistic",
              eval_metric = "logloss")

# the wp model
wp_model = model_func("t1_win", model_prepped_omit, 6, 2024, 23, 2015, 1, parameters)
#write.csv(wp_model, "wp_model_first_run.csv")

```

```{r}


# Record betting accuracy
pred_dat_final_wp = wp_model


# modify col names and calculate predicted wp
pred_dat_final_wp = pred_dat_final_wp %>% 
  rename(pred_t1_wp = preds,
         actual_t1_win = oc_var)




### SWITCH TO HOME/AWAY EVENTUALLY

pred_dat_final_wp$id_max = pmax(pred_dat_final_wp$t1_team, pred_dat_final_wp$t2_team)
pred_dat_final_wp$id_min = pmin(pred_dat_final_wp$t1_team, pred_dat_final_wp$t2_team)




# flip duplicate games and aggregate
merge_preds_wp = pred_dat_final_wp %>% 
  mutate(pred_t1_wp = ifelse(t1_team == id_max,pred_t1_wp, 
                                     1 - pred_t1_wp)) %>% 
  group_by(game_id) %>% 
  summarise(pred_t1_wp = mean(pred_t1_wp))

pred_dat_final_wp = pred_dat_final_wp %>% 
  filter(t1_team == id_max) %>% 
  select(-c(pred_t1_wp)) %>% 
  left_join(merge_preds_wp, by = c("game_id"))%>% 
  mutate(pred_t1_wp = round(pred_t1_wp, 4),
         pred_t1_win = ifelse(pred_t1_wp > .5, 1, 0)) %>% 
  select(-c(id_min, id_max))



write.csv(pred_dat_final_wp, "pred_dat_final_wp.csv")


```

<br>

### Total Points Model


```{r}


# tuned parameters
parameters = list(eta = .05,
              max.depth = 3, # Set max depth
              min_child_weight = 7, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
              subsample = .8, # Set proportion of training data to use in tree
              colsample_bytree = 1,
              
              
              nrounds = 110 , # Set number of rounds
              early_stopping_rounds = 30, # Set number of rounds to stop at if there is no improvement)
              
              verbose = 0, # 1 - Prints out fit
              nthread = 1,
              
              objective = "reg:squarederror",
              eval_metric = "rmse")

# the pd model
tp_model = model_func("total_points", model_prepped_omit, 6, 2024, 23, 2015, 1, parameters)
#write.csv(tp_model, "tp_model_test.csv")

```

```{r}

# Record betting accuracy

pred_dat_final_tp = tp_model


# modify col names and calculate predicted wp
pred_dat_final_tp = pred_dat_final_tp %>% 
  rename(pred_tp = preds,
         actual_tp = oc_var)





# flip duplicate games and aggregate
pred_dat_final_tp = pred_dat_final_tp %>% 
  group_by(game_id) %>% 
  summarize(pred_tp = mean(pred_tp),
            actual_tp = mean(actual_tp)) %>% 
  mutate(pred_tp = round(pred_tp, 2))




write.csv(pred_dat_final_tp, "pred_dat_final_tp.csv")


```



<br>

## Find Profitability

### Join all predictions

```{r}

pred_dat_final_pd = read.csv("pred_dat_final_pd.csv")[,-1]
pred_dat_final_tp = read.csv("pred_dat_final_tp.csv")[,-1]
pred_dat_final_wp = read.csv("pred_dat_final_wp.csv")[,-1]


# select cols to add back
info_lookup = join_bet %>% select(t1_book_spread, book_over_under, t1_team, t2_team, game_id, week, season, t1_home, neutral_site, t1_conference, t2_conference, over_odds, under_odds, over_val, under_val, t1_ml_odds, t1_spread_val, t1_spread_odds, t2_ml_odds, t2_spread_val, t2_spread_odds)


# join to all preds
pred_dat_final_pre = pred_dat_final_pd %>% 
  left_join(pred_dat_final_wp, by = c("t1_team", "t2_team", "game_id")) %>% 
  left_join(pred_dat_final_tp, by = c("game_id")) %>% 
  left_join(info_lookup, by = c("t1_team", "t2_team", "game_id")) 

```

```{r}

pred_dat_final_flip = pred_dat_final_pre %>% 
  mutate(actual_t1_point_diff = actual_t1_point_diff*-1,
         pred_t1_point_diff = pred_t1_point_diff*-1,
         actual_t1_win = ifelse(actual_t1_win==1,0,1),
         pred_t1_win = ifelse(pred_t1_win==1,0,1),
         pred_t1_wp = 1-pred_t1_wp,
         t1_book_spread = t1_book_spread*-1,
         t1_home = ifelse(t1_home==1,0,ifelse(neutral_site == 1, 0,1))
         ) %>% 
   mutate(
    across(
      .cols = c("t1_team", "t2_team", "t1_conference", "t2_conference", "t1_ml_odds", "t1_spread_val", "t1_spread_odds",
                "t2_ml_odds", "t2_spread_val", "t2_spread_odds"),
      .fns = ~ .x, .names = "{.col}_copy"
    )
  ) %>%
  mutate(
    t1_conference = t2_conference_copy,
    t2_conference = t1_conference_copy,
    t1_team = t2_team_copy,
    t2_team = t1_team_copy,
    t1_ml_odds      = t2_ml_odds_copy,
    t1_spread_val   = t2_spread_val_copy,
    t1_spread_odds  = t2_spread_odds_copy,
    t2_ml_odds      = t1_ml_odds_copy,
    t2_spread_val   = t1_spread_val_copy,
    t2_spread_odds  = t1_spread_odds_copy
  ) %>%
  select(-ends_with("_copy"))


pred_dat_final_all = bind_rows(pred_dat_final_pre, pred_dat_final_flip) 


pred_dat_final_all$id_max = pmax(pred_dat_final_all$t1_team, pred_dat_final_all$t2_team)
pred_dat_final_all$id_min = pmin(pred_dat_final_all$t1_team, pred_dat_final_all$t2_team)


pred_dat_final_all  = pred_dat_final_all %>% filter(t1_home | (neutral_site == 1 & id_max == t1_team)) %>%
  select(-c(id_max, id_min))






```


### Calculate Winnings

```{r}

  
winnings_calc = pred_dat_final_all  %>% 
  
  
  ### SPREAD
  
  # cols for if predicted and actual results covered for home
  mutate(book_t1_point_diff = t1_book_spread*-1) %>% 
  mutate(pred_t1_cover = ifelse(pred_t1_point_diff > book_t1_point_diff, 1, 0),
         actual_t1_cover = ifelse(actual_t1_point_diff > book_t1_point_diff, 1, 0)) %>% 
  select(-c(t1_book_spread)) %>% 
  # if we got spread correct and our return
  mutate(spread_correct = ifelse(pred_t1_cover == actual_t1_cover, 1, 0),
         spread_winnings = ifelse(spread_correct == 1 & actual_t1_cover == 1 & t1_spread_odds > 0, 
                                  1 + abs(t1_spread_odds)/100,
                            ifelse(spread_correct == 1 & actual_t1_cover == 1,
                                   1 + 100/abs(t1_spread_odds),
                            ifelse(spread_correct == 1 &  t2_spread_odds > 0, 
                                  1 + abs(t2_spread_odds)/100,
                            ifelse(spread_correct == 1,
                                   1 + 100/abs(t2_spread_odds),
                            0))))) %>% 
  # average bettor's spread returns
  mutate(naive_spread_winnings = ifelse(actual_t1_cover == 1 & t1_spread_odds > 0, 
                                  (1 + abs(t1_spread_odds)/100)/2,
                            ifelse(actual_t1_cover == 1,
                                   (1 + 100/abs(t1_spread_odds))/2,
                            ifelse(t2_spread_odds > 0, 
                                  (1 + abs(t2_spread_odds)/100)/2, 
                            (1 + 100/abs(t2_spread_odds))/2
                            )))) %>%
  # how much we predicted the book was off
  mutate(pred_vs_book_point_diff = abs(pred_t1_point_diff - book_t1_point_diff)) %>% 
  
  
  
  
  
  ### MONEYLINE
  
  # convert win prob to ml value
  mutate(t1_ml_prob = ifelse(t1_ml_odds > 0, 100 / (t1_ml_odds + 100), -t1_ml_odds / (-t1_ml_odds + 100)),
         t2_ml_prob = ifelse(t2_ml_odds > 0, 100 / (t2_ml_odds + 100), -t2_ml_odds / (-t2_ml_odds + 100))) %>% 
  # how much value is there
  mutate(pred_t1_value = ifelse(pred_t1_wp > t1_ml_prob, 1, 0),
         pred_t2_value = ifelse((1 - pred_t1_wp) > t2_ml_prob, 1, 0)) %>% 
  # if we got correct our return
  mutate(ml_correct = ifelse((pred_t1_value == 1 & actual_t1_win == 1) | (pred_t2_value == 1 & actual_t1_win == 0), 1, 0),
         ml_winnings = ifelse(ml_correct == 1 & actual_t1_win == 1 & t1_ml_odds > 0, 
                                  1 + abs(t1_ml_odds)/100,
                            ifelse(ml_correct == 1 & actual_t1_win == 1,
                                   1 + 100/abs(t1_ml_odds),
                            ifelse(ml_correct == 1 &  t2_ml_odds > 0, 
                                  1 + abs(t2_ml_odds)/100,
                            ifelse(ml_correct == 1,
                                   1 + 100/abs(t2_ml_odds),
                            ifelse(pred_t1_value + pred_t2_value == 0, 1,
                                   0)))))) %>% 
      # average bettor's ml returns
  mutate(naive_ml_winnings = ifelse(actual_t1_win == 1 & t1_ml_odds > 0, 
                                  (1 + abs(t1_ml_odds)/100)/2,
                            ifelse(actual_t1_win == 1,
                                   (1 + 100/abs(t1_ml_odds))/2,
                            ifelse(t2_ml_odds > 0, 
                                  (1 + abs(t2_ml_odds)/100)/2, 
                            (1 + 100/abs(t2_ml_odds))/2
                            )))) %>%
  # how much we predicted the book was off
    mutate(pred_vs_book_ml_value = ifelse(pred_t1_value == 1, round(pred_t1_wp - t1_ml_prob, 4), ifelse(pred_t2_value == 1, round((1-pred_t1_wp) - t2_ml_prob, 4),0))) %>% 
  
  
  
  
  
  ### OVER/UNDER
  
  
  # cols for if predicted and actual results covered for over/under
  mutate(pred_over = ifelse(pred_tp > book_over_under, 1, 0),
         actual_over = ifelse(actual_tp > book_over_under, 1, 0)) %>%
  # if we got spread correct and our return
  mutate(ou_correct = ifelse(pred_over == actual_over, 1, 0),
         ou_winnings = ifelse(ou_correct == 1 & actual_over == 1 & over_odds > 0, 
                                  1 + abs(over_odds)/100,
                            ifelse(ou_correct == 1 & actual_over == 1,
                                   1 + 100/abs(over_odds),
                            ifelse(ou_correct == 1 &  under_odds > 0, 
                                  1 + abs(under_odds)/100,
                            ifelse(ou_correct == 1,
                                   1 + 100/abs(under_odds),
                            0))))) %>% 
  # average bettor's spread returns
  mutate(naive_ou_winnings = ifelse(actual_over == 1 & over_odds > 0, 
                                  (1 + abs(over_odds)/100)/2,
                            ifelse(actual_over == 1,
                                   (1 + 100/abs(over_odds))/2,
                            ifelse(under_odds > 0, 
                                  (1 + abs(under_odds)/100)/2, 
                            (1 + 100/abs(under_odds))/2
                            )))) %>%
  # how much we predicted the book was off
  mutate(pred_vs_book_tp = abs(pred_tp - book_over_under))
  
```





# Write out

```{r}

# mark season ids  for saved df
mark = winnings_calc %>% arrange(season, week) %>% mutate(order = row_number())
mark_min_week = mark[1,]$week
mark_min_season = mark[1,]$season
mark_max_week = mark[dim(mark)[1],]$week
mark_max_season = mark[dim(mark)[1],]$season



# # read in old predictions and bind w new
# old_predictions = read.csv("final_prediction_df.csv")
# winnings_calc_fin = bind_rows(old_predictions, winnings_calc)
# 
# 
# # save final df and these specific predictions in case screw up
#write.csv(winnings_calc_fin, "final_prediction_df.csv")
# write.csv(winnings_calc, paste0("winnings_calc_saved_dfs/prediction", mark_min_season, mark_min_week, "to", mark_max_season, mark_max_week, ".csv"))


```


### Find winning values overall

```{r}

#

sum(winnings_calc$spread_winnings) / length(winnings_calc$spread_winnings)

sum(winnings_calc$naive_spread_winnings) / length(winnings_calc$spread_winnings)







sum(winnings_calc$ml_winnings, na.rm = TRUE) / length((winnings_calc %>% filter(!is.na(ml_winnings)))$ml_winnings)

sum(winnings_calc$naive_ml_winnings, na.rm = TRUE) / length((winnings_calc %>% filter(!is.na(ml_winnings)))$ml_winnings)








sum(winnings_calc$ou_winnings) / length(winnings_calc$ou_winnings)

sum(winnings_calc$naive_ou_winnings) / length(winnings_calc$ou_winnings)
  
```

<br>

## Load in Team Logos


```{r}

# load team info
team_info = cfbd_team_info()

# select cols
team_info = team_info %>% 
  select(school, color, logo)

# write truncated result out
#write.csv(team_info, "team_info.csv")
#team_info = read.csv("team_info.csv")[,-1]
```


<br>

## Create Theoretical Games


### Find most recent stats


```{r}

parameters_book = list(eta = .05,
              max.depth = 3, # Set max depth
              min_child_weight = 7, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
              subsample = .8, # Set proportion of training data to use in tree
              colsample_bytree = 1,
              
              
              nrounds = 110 , # Set number of rounds
              early_stopping_rounds = 30, # Set number of rounds to stop at if there is no improvement)
              
              verbose = 0, # 1 - Prints out fit
              nthread = 1,
              
              objective = "reg:squarederror",
              eval_metric = "rmse")




```


```{r}



# fake rows
theor_prepped_omit = model_prepped_omit %>%
  filter(season == current_season) %>% 
  arrange(desc(week)) %>% 
  group_by(t1_team) %>% 
  mutate(desc_order = row_number()) %>% 
  filter(desc_order == 1) %>% 
  select(-c(desc_order)) %>% 
  ungroup()



# get rid of team 2 and betting stuff
theor_prepped_omit = theor_prepped_omit %>% 
  mutate(across(all_of(grep("t2", names(theor_prepped_omit))), ~ NA))

theor_prepped_omit = theor_prepped_omit %>% 
  mutate(across(all_of(grep("_odds", names(theor_prepped_omit))), ~ NA))

theor_prepped_omit = theor_prepped_omit %>% 
  mutate(across(all_of(grep("_val", names(theor_prepped_omit))), ~ NA))


# make non-feature cols NA
theor_prepped_omit = theor_prepped_omit %>% 
  mutate(across(all_of(c("t1_book_spread", "game_id", "t1_points", "t2_points", "total_points", "t1_win", "t1_point_diff", "conference_game")), ~ NA))


  

```


<br>

### Create fake games

```{r}



# create t1 and t2 dfs
theor_prepped_t1 = theor_prepped_omit %>% 
   select(contains("t1"))

theor_prepped_t2 = theor_prepped_omit %>% 
   select(-c(t1_book_spread)) %>% 
   select(contains("t1"))

names(theor_prepped_t2) <- gsub("t1", "t2", names(theor_prepped_t2))




# create fake games thru combinations
teams1 = unique(theor_prepped_omit$t1_team)
teams2 = unique(theor_prepped_omit$t1_team)

combinations <- expand.grid(t1_team = teams1, t2_team = teams2) %>% 
  filter(t1_team != t2_team)





# create fake game df
theor_prepped_frame = theor_prepped_omit %>% filter(is.na(t1_team))
theor_prepped_start = as.data.frame(matrix(NA, nrow = dim(combinations)[1]), ncol = 1)
theor_prepped_start$t1_team = combinations$t1_team
theor_prepped_start$t2_team = combinations$t2_team


# join in stats
theor_prepped_start = theor_prepped_start %>% 
  left_join(theor_prepped_t1, by = "t1_team") %>% 
  left_join(theor_prepped_t2, by = "t2_team")


# modify structure of cols
theor_prepped_frame$t2_team = as.character(theor_prepped_frame$t2_team)
theor_prepped_frame$t2_conference = as.character(theor_prepped_frame$t2_conference)
theor_prepped_home = bind_rows(theor_prepped_frame, theor_prepped_start) %>% 
    mutate(week = current_week,
         completed = FALSE,
         season = current_season,
         t1_home = 1,
         neutral_site = 0)

theor_prepped_away = theor_prepped_home %>% 
  mutate(t1_home = 0)

theor_prepped_neutral = theor_prepped_away %>% 
  mutate(neutral_site = 1)

theor_prepped_joined = bind_rows(theor_prepped_home, theor_prepped_away, theor_prepped_neutral)



# predict and add book variables for model
book_spread_model = book_function("t1_book_spread", theor_prepped_joined)
book_over_under_model = book_function("book_over_under", theor_prepped_joined)

theor_prepped_joined$book_over_under = book_over_under_model
theor_prepped_joined$t1_book_spread = book_spread_model





```

```{r}

# load in most recent pd model info
theor_model = xgb.load("most_recent_t1_point_diff_model.model")
theor_vars = read.csv("most_recent_t1_point_diffmodel_var_list.csv")[,2]


# create test matrix for theoretical games
theor_test = theor_prepped_joined %>% select(theor_vars, t1_home, neutral_site, t1_team, t2_team, t1_conference, t2_conference)
num_predictors_theor = length(theor_vars)

test_matrix_theor = xgb.DMatrix(data = as.matrix(theor_test[,1:num_predictors_theor]))



# predict
preds = predict(theor_model, test_matrix_theor)
pred_dat_final_theor = cbind.data.frame(pred_t1_point_diff = preds, t1_team = theor_test$t1_team, t2_team = theor_test$t2_team, t1_home = theor_test$t1_home, neutral_site = theor_test$neutral_site, t1_conference = theor_test$t1_conference, t2_conference = theor_test$t2_conference)




# combine preds into df
pred_dat_final_theor = pred_dat_final_theor %>% 
  mutate(id_max = ifelse(t1_home ==1, t1_team, ifelse(neutral_site == 1, pmax(pred_dat_final_theor$t1_team, pred_dat_final_theor$t2_team), t2_team))) %>% 
    mutate(id_min = ifelse(t1_home ==1, t2_team, ifelse(neutral_site == 1, pmin(pred_dat_final_theor$t1_team, pred_dat_final_theor$t2_team), t1_team)))

pred_dat_final_theor$game_id = 1:dim(pred_dat_final_theor)[1]


merge_preds_theor = pred_dat_final_theor %>% 
  mutate(pred_t1_point_diff = ifelse(t1_team == id_max,pred_t1_point_diff, 
                                     pred_t1_point_diff*-1)) %>% 
  group_by(game_id) %>% 
  summarise(pred_t1_point_diff = mean(pred_t1_point_diff))


pred_dat_final_theor = pred_dat_final_theor %>% 
  filter(t1_team == id_max) %>% 
  select(-c(pred_t1_point_diff)) %>% 
  left_join(merge_preds_theor, by = c("game_id"))%>% 
  mutate(pred_t1_point_diff = round(pred_t1_point_diff, 2)) %>% 
  select(-c(id_min, id_max))





# duplicate rows and flip one for easier aggregation by team
pred_dat_final_theor2 = pred_dat_final_theor %>% 
  mutate(pred_t1_point_diff = pred_t1_point_diff*-1) %>% 
  mutate(t1_home = ifelse(neutral_site == 1, 0, ifelse(t1_home == 1, 0, 1))) %>% 
  mutate(
    across(
      .cols = c("t1_team", "t2_team", "t1_conference", "t2_conference"),
      .fns = ~ .x, .names = "{.col}_copy"
    )
  ) %>%
  mutate(
    t1_conference = t2_conference_copy,
    t2_conference = t1_conference_copy,
    t1_team = t2_team_copy,
    t2_team = t1_team_copy,
    ) %>%
  select(-ends_with("_copy"))


pred_dat_final_theor = bind_rows(pred_dat_final_theor, pred_dat_final_theor2) %>% 
  mutate(t1_win = ifelse(pred_t1_point_diff > 0, 1, 0),
         conference_game = ifelse(t1_conference == t2_conference, 1, 0),
         week = current_week) %>% 
  left_join(team_info %>% rename(t1_team = school, t1_color = color, t1_logo = logo), by = "t1_team") %>% 
  left_join(team_info %>% rename(t2_team = school, t2_color = color, t2_logo = logo), by = "t2_team") %>%
  mutate(winning_logo = ifelse(pred_t1_point_diff >0, t1_logo, t2_logo),
         losing_logo = ifelse(pred_t1_point_diff <=0, t1_logo, t2_logo),
         winning_color = ifelse(pred_t1_point_diff >0, t1_color, t2_color),
         losing_logo = ifelse(pred_t1_point_diff <=0, t1_logo, t2_logo),
         winning_team = ifelse(t1_win == 1, t1_team, t2_team),
         losing_team = ifelse(t1_win == 0, t1_team, t2_team),
         point_margin = abs(pred_t1_point_diff))



```

```{r}

# aggregate by team

theor_agg_conf = pred_dat_final_theor %>% filter(conference_game == 1) %>% group_by(t1_team) %>% summarise(win_perc_conf = round(mean(t1_win),2)*100, point_diff_conf = round(mean(pred_t1_point_diff),2)) %>% arrange(desc(win_perc_conf), desc(point_diff_conf)) 

theor_agg = pred_dat_final_theor %>% group_by(t1_team, t1_conference) %>% summarise(win_perc = round(mean(t1_win),2)*100, point_diff = round(mean(pred_t1_point_diff),2)) %>% arrange(desc(win_perc), desc(point_diff)) %>% left_join(theor_agg_conf, by = "t1_team") %>% ungroup %>%  mutate(Rank = row_number()) %>% group_by(t1_conference) %>% mutate(`Conf Rank` = row_number()) %>% ungroup() %>% 
  rename(Team = t1_team,
         Conf = t1_conference,
         `Pred Win%` = win_perc,
         `Pred PD/g` = point_diff,
         `Pred Conf Win%` = win_perc_conf,
         `Pred Conf PD` = point_diff_conf)




```





```{r}
# write theoretical data out
write.csv(theor_agg, "theoretical_agg_test.csv")
write.csv(pred_dat_final_theor, "theor_prepped_test.csv")

```


<br>

## Test Read-in


```{r}

wc_test = read.csv("final_prediction_df.csv")[,-1]

wc_test2 = wc_test %>% 
  filter(season != 2024 | week <= 6)


wc_test7 = wc_test %>% 
  filter(season == 2024 & week == 7) %>% 
  mutate(actual_t1_cover = NA,
         spread_correct = NA,
         actual_t1_point_diff = NA,
         actual_t1_win = NA,
         actual_tp = NA,
         spread_winnings = NA,
         naive_spread_winnings = NA,
         ml_correct = NA,
         ml_winnings = NA,
         naive_ml_winnings = NA,
         actual_over = NA,
         ou_correct = NA,
         ou_winnings = NA,
         naive_ou_winnings = NA)


wc_test_final = bind_rows(wc_test2, wc_test7)

write.csv(wc_test_final, "final_prediction_df_test.csv")

```















