---
title: "CFB Model Training"
author: "The Five Horsemen"
date: "2024-10-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



### Install Packages
```{r, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(rsample)
library(mice)
library(fastDummies)
library(xgboost)
library(Metrics)
library(caret)
```

<br>

# *CFB Data Data Prep*

### Load Data

```{r, warning=FALSE}

# model data
cfb_model_data = read.csv(gzfile("cfb_model_data_prep_full_check.csv.gz"))


```


### Initial Wrangling

```{r}

# current weeks, useful for later predicting this week's games
current_week = 24
current_season = 2024


# df with only rows with both fbs team (fcs data incomplete, easier to exclude these)
# later weeks to let stats accumulate, data before 2015 incomplete 
fbs_only = cfb_model_data %>% 
  filter(t1_division == "fbs" & t2_division == "fbs") %>% 
  filter(week > 3,
         season > 2014)%>% 
  select(-c(t1_division, t2_division)) %>% 
  mutate(conference_game = ifelse(conference_game, 1, 0))
  

# treat NAs, add lag as the stat if there isn't one for a given week
# filter out games that are incomplete, unless for this week
model_prepped_orig = fbs_only %>% 
  filter((completed == TRUE & !is.na(precipitation_code)) | (week == current_week & season == current_season),
         ) %>% # get rid of non-played games
  
  # replace NAs from pbp with lag for each team/season window, both for t1 and t2
  # best estimate of these stats, if available
  group_by(season, t1_team) %>%
  arrange(t1_team, season, week) %>% 
  mutate(across(starts_with("t1_rol"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup() %>% 
  group_by(season, t2_team) %>% 
  arrange(t2_team, season, week) %>% 
  mutate(across(starts_with("t2_rol"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup() %>% 
  select(-c(rol_win_l1, "rol_loss_l1", "t1_moneyline", "t2_moneyline")) %>% 
  mutate(actual_over = ifelse(total_points > book_over_under, 1, 0)) %>% 
  mutate(t1_actual_cover = ifelse(t1_point_diff > t1_book_spread*-1, 1, 0))




```

### NA Check
```{r}

# Calculate the percentage of NAs in each column
na_rate <- colMeans(is.na(model_prepped_orig))

# Create a new data frame with the NA percentages
df_na_percentage <- data.frame(
  column = colnames(model_prepped_orig),
  na_rate = na_rate
)

# display
df_na_percentage %>%
  arrange(desc(na_rate))
```



### Arrange Data
```{r}

# dummy cols 
model_prepped_dummy = model_prepped_orig %>% 
  rename(pc = precipitation_code) %>% 
  dummy_cols('pc') %>% 
  select(-pc)


# rearrange col order (makes easier when looking at predictions later)
move_cols = c("pc_no_rain", "pc_light_rain", "pc_moderate_rain", "pc_heavy_rain", "week", "neutral_site", "t1_home", "t2_home", "conference_game", "season", "t1_point_diff", "t1_win", "total_points", "t1_actual_cover", "actual_over", "t1_points", "t2_points", "game_id", "t1_team", "t2_team", "t1_conference", "t2_conference", "completed")

pd_vars = scan("test_pd_vars.txt", what = "character", sep = "\n")

model_prepped_moved = model_prepped_dummy[, c(setdiff(names(model_prepped_dummy), move_cols), move_cols)]

```



## PD Data
```{r}

model_prepped_moved_pd = model_prepped_moved %>% select(pd_vars, move_cols)

model_prepped_moved_pd = model_prepped_moved_pd %>% select(-c(grep("rain", names(model_prepped_moved_pd)))) 

#model_prepped_moved_pd = model_prepped_moved_pd %>% select(-c(wind_speed))

```




### Omit Remaining NA Rows
```{r}
# omit NA cols (only one thousand)
model_prepped_omit_pd = na.omit(model_prepped_moved_pd) 


```






<br>

# *Point Diff Modeling*

### Tuned Model 

```{r}





parameters = list(eta = .05,
              max.depth = 3, # Set max depth
              min_child_weight = 7, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
              subsample = .8, # Set proportion of training data to use in tree
              colsample_bytree = 1,
              
              
              nrounds = 110 , # Set number of rounds
              early_stopping_rounds = 30, # Set number of rounds to stop at if there is no improvement)
              
              verbose = 0, # 1 - Prints out fit
              nthread = 1,
              
              eval_metric = "rmse")


# oc_var = "t1_point_diff"
# 
# num_predictors = 196
# 
# data = model_prepped_omit_pd
# 
# yr_length = 7
# 
# real_yr = 2024
# 
# real_wk = 4
# 
# initial_yr = 2017
# 
# params = parameters
# 
# yr = 2023
# 
# wk= 15



model_func = function(oc_var, num_predictors, data, yr_length, real_yr, real_wk, initial_yr, params){

    set.seed(844)
  
    year_range = c((initial_yr + yr_length):real_yr)
    
    for (yr in year_range){
      
      print(yr)
      iter = 0
      
      current_yr = yr
      start_yr = current_yr - yr_length
      
      if (current_yr %in% c(2010)){
        week_range = c(4:16, 20, 22, 23)
      } else if (current_yr == 2020){
        week_range = c(5:15,20,22,23)
      } else if (current_yr <= 2023) {
        week_range = c(4:15, 20, 22, 23)
      } else{
        week_range = c(4:15, 20:23)
      }
      
      if (current_yr == real_yr){
        week_range = week_range[week_range<=real_wk]
      }
      
      
      for (wk in week_range){
        
        print(wk)
        iter = iter + 1
        
        current_wk = wk
        
        train = data %>% 
          filter((season == start_yr & week > current_wk) | (season > start_yr & season < current_yr) | (season == current_yr & week < current_wk))
        
        test = data %>% 
          filter(season == current_yr & week == current_wk)
        
        
        names(train)[grep(oc_var, names(train))] = "oc_var"
        names(test)[grep(oc_var, names(test))] = "oc_var"
        
        
            # Create training matrix
        train_matrix = xgb.DMatrix(data = as.matrix(train[,1:num_predictors]), 
                                      label = as.integer(train$oc_var))
        
        # Create training matrix
        test_matrix = xgb.DMatrix(data = as.matrix(test[,1:num_predictors]), 
                                      label = as.numeric(test$oc_var))
        
        
    
        
        
        new_params = c(params, data = train_matrix)
        
        model = do.call(xgboost, new_params)
        
        
        preds = predict(model, test_matrix)
        new_df = cbind.data.frame(preds, test$oc_var, test$game_id)
        
        
        if (yr == initial_yr + yr_length & iter == 1){
          pred_df = new_df
        } else{
          pred_df = bind_rows(pred_df, new_df)
        }
        
        
      }
      
    }
    
    
    return(pred_df)
    
}    

```

```{r}

rw_8 = model_func("t1_point_diff", 197, model_prepped_omit_pd, 8, 2024, 23, 2015, parameters)

rw_7 = model_func("t1_point_diff", 197, model_prepped_omit_pd, 7, 2024, 23, 2015, parameters)

rw_6 = model_func("t1_point_diff", 197, model_prepped_omit_pd, 6, 2024, 23, 2015, parameters)

rw_5 = model_func("t1_point_diff", 197, model_prepped_omit_pd, 5, 2024, 23, 2015, parameters)

rw_4 = model_func("t1_point_diff", 197, model_prepped_omit_pd, 4, 2024, 23, 2015, parameters)

rw_3 = model_func("t1_point_diff", 197, model_prepped_omit_pd, 3, 2024, 23, 2015, parameters)


# write.csv(rw_8, "rw_8.csv")
# write.csv(rw_7, "rw_7.csv")
# write.csv(rw_6, "rw_6.csv")
# write.csv(rw_5, "rw_5.csv")
# write.csv(rw_4, "rw_4.csv")
# write.csv(rw_3, "rw_3.csv")
# 
# rw_8 = read.csv("rw_8.csv")[,-1]
# rw_7 = read.csv("rw_7.csv")[,-1]
# rw_6 = read.csv("rw_6.csv")[,-1]
# rw_5 = read.csv("rw_5.csv")[,-1]
# rw_4 = read.csv("rw_4.csv")[,-1]
# rw_3 = read.csv("rw_3.csv")[,-1]




```


```{r}

join_df = model_prepped_omit_pd %>% 
  select(game_id, t1_point_diff, t1_book_spread, t1_actual_cover, t1_win, week, season, t1_team, t2_team)


#name = "rw_8"


df_list <- list("rw_8" = rw_8, "rw_7" = rw_7, "rw_6" = rw_6, "rw_5" = rw_5, "rw_4" = rw_4, "rw_3" = rw_3)
it = 0


for (name in names(df_list)) {
  it = it+1
  
  df <- df_list[[name]]
  colnames(df) = c("model_pred_pd", "t1_point_diff", "game_id")
  
  df = left_join(df, join_df, by = c("game_id", "t1_point_diff"))
  
  df = df %>% 
    mutate(window = name) %>% 
    mutate(book_pred_pd = t1_book_spread * -1) %>% 
    select(-c(t1_book_spread)) %>% 
    mutate(model_pred_cover = ifelse(model_pred_pd > book_pred_pd, 1, 0)) %>% 
    mutate(model_pred_win = ifelse(model_pred_pd > 0, 1, 0))
  
  
  
  if (it == 1){
    window_test_df = df
  } else{
    window_test_df = bind_rows(df, window_test_df)
  }
  
  
  
  
  # error measures
  rmse = rmse(df$t1_point_diff, df$model_pred_pd) 
  mse = mse(df$t1_point_diff, df$model_pred_pd)
  mae = mae(df$t1_point_diff, df$model_pred_pd)
  
  
  win_cm = confusionMatrix(as.factor(df$model_pred_win),
                                     as.factor(df$t1_win), positive = "1")
  win_acc = win_cm$overall[1]
  
  
  spread_cm = confusionMatrix(as.factor(df$model_pred_cover),
                                     as.factor(df$t1_actual_cover), positive = "1")
  spread_acc = spread_cm$overall[1]
  
  yr = "All"
  
  
  
  
  if (it == 1){
    accuracy_df = cbind.data.frame(name, yr, rmse, mse, mae, win_acc, spread_acc)
  } else{
    new_accuracy_df = cbind.data.frame(name, yr, rmse, mse, mae, win_acc, spread_acc)
    accuracy_df = bind_rows(accuracy_df, new_accuracy_df)
  }
  
  
  
  
  uniq_yr = unique(df$season)
  it2 = 0
  
  for (yr in uniq_yr){
      it2 = it2+1
    
      df_yr = df %>% filter(season == yr)
      
      # error measures
      rmse_yr = rmse(df_yr$t1_point_diff, df_yr$model_pred_pd) 
      mse_yr = mse(df_yr$t1_point_diff, df_yr$model_pred_pd)
      mae_yr = mae(df_yr$t1_point_diff, df_yr$model_pred_pd)
      
      
      win_cm_yr = confusionMatrix(as.factor(df_yr$model_pred_win),
                                         as.factor(df_yr$t1_win), positive = "1")
      win_acc_yr = win_cm_yr$overall[1]
      
      
      spread_cm_yr = confusionMatrix(as.factor(df_yr$model_pred_cover),
                                         as.factor(df_yr$t1_actual_cover), positive = "1")
      spread_acc_yr = spread_cm_yr$overall[1]
      
      
      
      
      if (it == 1 & it2 == 1){
        accuracy_df_yr = cbind.data.frame(name, yr, rmse_yr, mse_yr, mae_yr, win_acc_yr, spread_acc_yr)
      } else{
        new_accuracy_df_yr = cbind.data.frame(name, yr, rmse_yr, mse_yr, mae_yr, win_acc_yr, spread_acc_yr)
        accuracy_df_yr = bind_rows(accuracy_df_yr, new_accuracy_df_yr)
      }
      
      
    
  }
  
  
  
  
  
  
  
}





```


```{r}

spread_acc = ggplot(accuracy_df_yr, aes(x = yr, y = spread_acc_yr, color = name, group = name)) +
  geom_line(size = 1) +  # Line plot
  geom_point(size = 2) +  # Add points for better visibility
  geom_hline(yintercept = .525, linetype = "dashed", color = "darkgray", size = .4) + 
  theme_minimal() +  # Clean theme
  labs(title = "Spread Accuracy",
       x = "Year", 
       y = "Acc",
       color = "Category")  # Legend title


win_acc = ggplot(accuracy_df_yr, aes(x = yr, y = win_acc_yr, color = name, group = name)) +
  geom_line(size = 1) +  # Line plot
  geom_point(size = 2) +  # Add points for better visibility
  theme_minimal() +  # Clean theme
  labs(title = "Win Accuracy",
       x = "Year", 
       y = "Acc",
       color = "Category")  # Legend title



rmse = ggplot(accuracy_df_yr, aes(x = yr, y = rmse_yr, color = name, group = name)) +
  geom_line(size = 1) +  # Line plot
  geom_point(size = 2) +   
  theme_minimal() +  # Clean theme
  labs(title = "RMSE",
       x = "Year", 
       y = "RMSE",
       color = "Category")  # Legend title



spread_acc
win_acc
rmse


```



### Linear Prediction Error
```{r}



# predictions
pred_dat_final_pd <- cbind.data.frame(boost_preds_final_pd, test$t1_point_diff)

# error measures
rmse(test$t1_point_diff, boost_preds_final_pd) 
mse(test$t1_point_diff, boost_preds_final_pd)
mae(test$t1_point_diff, boost_preds_final_pd)


head(pred_dat_final_pd) # print prediction df





```

### Win/Loss Prediction Accuracy
```{r}

# analyze predictive ability on wins/losses
pred_dat_win_final_pd = pred_dat_final_pd %>% 
  mutate(actual_win = ifelse(`test$t1_point_diff` > 0, 1, 0)) %>% 
  mutate(pred_win = ifelse(boost_preds_final_pd > 0, 1, 0))


# Create confusion matrix
conf_matrix_final_pd <- confusionMatrix(as.factor(pred_dat_win_final_pd$pred_win),
                                     as.factor(pred_dat_win_final_pd$actual_win), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix_final_pd)

```


### Spread Prediction Accuracy
```{r}

# create spread analysis df
pred_dat_spread_final_pd = pred_dat_final_pd
pred_dat_spread_final_pd$t1_book_spread = test$t1_book_spread
pred_dat_spread_final_pd = pred_dat_spread_final_pd %>% 
  rename(t1_book_point_diff = t1_book_spread,
         t1_actual_point_diff = `test$t1_point_diff`) %>% 
  mutate(t1_book_point_diff = t1_book_point_diff*-1) %>% 
  mutate(pred_cover = ifelse(boost_preds_final_pd > t1_book_point_diff, 1, 0),
         actual_cover = ifelse(t1_actual_point_diff > t1_book_point_diff, 1, 0)) 


# Create confusion matrix
conf_matrix_spread <- confusionMatrix(as.factor(pred_dat_spread_final_pd$pred_cover),
                                     as.factor(pred_dat_spread_final_pd$actual_cover), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix_spread)
```



### Actual v Predicted Plot

```{r}
# combine into df
plot_dat_pd <- cbind.data.frame(test$t1_point_diff,boost_preds_final_pd)
names(plot_dat_pd) <- c("actual", "predicted")

# plot
ggplot(plot_dat_pd, aes(x = actual, y = predicted)) +
  geom_point() +
  geom_smooth()
```


### Variable Importance, Top 10
```{r}
# Extract importance
imp_mat_pd <- xgb.importance(model = bst_final_pd)
# Plot importance (top 10 variables)
xgb.plot.importance(imp_mat_pd, top_n = 10)
```








```{r}
rw_8_20pr = model_func("t1_point_diff", c(1:21,100:119), model_prepped_omit_pd, 8, 2024, 23, 2015, parameters)

rw_7_20pr = model_func("t1_point_diff", c(1:21,100:119), model_prepped_omit_pd, 7, 2024, 23, 2015, parameters)

rw_6_20pr = model_func("t1_point_diff", c(1:21,100:119), model_prepped_omit_pd, 6, 2024, 23, 2015, parameters)

rw_5_20pr = model_func("t1_point_diff", c(1:21,100:119), model_prepped_omit_pd, 5, 2024, 23, 2015, parameters)

rw_4_20pr = model_func("t1_point_diff", c(1:21,100:119), model_prepped_omit_pd, 4, 2024, 23, 2015, parameters)

rw_3_20pr = model_func("t1_point_diff", c(1:21,100:119), model_prepped_omit_pd, 3, 2024, 23, 2015, parameters)
```


```{r}

join_df = model_prepped_omit_pd %>% 
  select(game_id, t1_point_diff, t1_book_spread, t1_actual_cover, t1_win, week, season, t1_team, t2_team)


#name = "rw_8"


df_list <- list("rw_8_20pr" = rw_8_20pr, "rw_7_20pr" = rw_7_20pr, "rw_6_20pr" = rw_6_20pr, "rw_5_20pr" = rw_5_20pr, "rw_4_20pr" = rw_4_20pr, "rw_3_20pr" = rw_3_20pr)
it = 0

for (name in names(df_list)) {
  it = it+1
  
  df <- df_list[[name]]
  colnames(df) = c("model_pred_pd", "t1_point_diff", "game_id")
  
  df = left_join(df, join_df, by = c("game_id", "t1_point_diff"))
  
  df = df %>% 
    mutate(window = name) %>% 
    mutate(book_pred_pd = t1_book_spread * -1) %>% 
    select(-c(t1_book_spread)) %>% 
    mutate(model_pred_cover = ifelse(model_pred_pd > book_pred_pd, 1, 0)) %>% 
    mutate(model_pred_win = ifelse(model_pred_pd > 0, 1, 0))
  
  
  
  if (it == 1){
    window_test_df = df
  } else{
    window_test_df = bind_rows(df, window_test_df)
  }
  
  
  
  
  # error measures
  rmse = rmse(df$t1_point_diff, df$model_pred_pd) 
  mse = mse(df$t1_point_diff, df$model_pred_pd)
  mae = mae(df$t1_point_diff, df$model_pred_pd)
  
  
  win_cm = confusionMatrix(as.factor(df$model_pred_win),
                                     as.factor(df$t1_win), positive = "1")
  win_acc = win_cm$overall[1]
  
  
  spread_cm = confusionMatrix(as.factor(df$model_pred_cover),
                                     as.factor(df$t1_actual_cover), positive = "1")
  spread_acc = spread_cm$overall[1]
  
  yr = "All"
  
  
  
  
  if (it == 1){
    accuracy_df = cbind.data.frame(name, yr, rmse, mse, mae, win_acc, spread_acc)
  } else{
    new_accuracy_df = cbind.data.frame(name, yr, rmse, mse, mae, win_acc, spread_acc)
    accuracy_df = bind_rows(accuracy_df, new_accuracy_df)
  }
  
  
  
  
  uniq_yr = unique(df$season)
  it2 = 0
  
  for (yr in uniq_yr){
      it2 = it2+1
    
      df_yr = df %>% filter(season == yr)
      
      # error measures
      rmse_yr = rmse(df_yr$t1_point_diff, df_yr$model_pred_pd) 
      mse_yr = mse(df_yr$t1_point_diff, df_yr$model_pred_pd)
      mae_yr = mae(df_yr$t1_point_diff, df_yr$model_pred_pd)
      
      
      win_cm_yr = confusionMatrix(as.factor(df_yr$model_pred_win),
                                         as.factor(df_yr$t1_win), positive = "1")
      win_acc_yr = win_cm_yr$overall[1]
      
      
      spread_cm_yr = confusionMatrix(as.factor(df_yr$model_pred_cover),
                                         as.factor(df_yr$t1_actual_cover), positive = "1")
      spread_acc_yr = spread_cm_yr$overall[1]
      
      
      
      
      if (it == 1 & it2 == 1){
        accuracy_df_yr = cbind.data.frame(name, yr, rmse_yr, mse_yr, mae_yr, win_acc_yr, spread_acc_yr)
      } else{
        new_accuracy_df_yr = cbind.data.frame(name, yr, rmse_yr, mse_yr, mae_yr, win_acc_yr, spread_acc_yr)
        accuracy_df_yr = bind_rows(accuracy_df_yr, new_accuracy_df_yr)
      }
      
      
    
  }
  
  
  
  
  
  
  
}





```


```{r}

spread_acc = ggplot(accuracy_df_yr, aes(x = yr, y = spread_acc_yr, color = name, group = name)) +
  geom_line(size = 1) +  # Line plot
  geom_point(size = 2) +  # Add points for better visibility
  geom_hline(yintercept = .525, linetype = "dashed", color = "darkgray", size = .4) + 
  theme_minimal() +  # Clean theme
  labs(title = "Spread Accuracy",
       x = "Year", 
       y = "Acc",
       color = "Category")  # Legend title


win_acc = ggplot(accuracy_df_yr, aes(x = yr, y = win_acc_yr, color = name, group = name)) +
  geom_line(size = 1) +  # Line plot
  geom_point(size = 2) +  # Add points for better visibility
  theme_minimal() +  # Clean theme
  labs(title = "Win Accuracy",
       x = "Year", 
       y = "Acc",
       color = "Category")  # Legend title



rmse = ggplot(accuracy_df_yr, aes(x = yr, y = rmse_yr, color = name, group = name)) +
  geom_line(size = 1) +  # Line plot
  geom_point(size = 2) +   
  theme_minimal() +  # Clean theme
  labs(title = "RMSE",
       x = "Year", 
       y = "RMSE",
       color = "Category")  # Legend title



spread_acc
win_acc
rmse


```
